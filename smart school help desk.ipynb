{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iPdrhLSJnX_d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPdrhLSJnX_d",
        "outputId": "b728aa4f-3b7e-4fdf-8124-63cf73412cf6"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.7.0' requires the ipykernel package.\n",
            "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
            "\u001b[1;31mOr install 'ipykernel' using the command: '\"c:/Users/B.saikarthik Yadav/AppData/Local/Programs/Python/Python37/python.exe\" -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "pip install gradio faiss-cpu sentence-transformers requests langchain\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YKjV-h3OoSjJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "YKjV-h3OoSjJ",
        "outputId": "01b6f3cf-85e6-4b37-c765-c704b9db71b1"
      },
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# üè´ School Parent Helpdesk Chatbot (Gradio + FAISS + NVIDIA RAG)\n",
        "# Works directly in Google Colab\n",
        "# ========================================\n",
        "\n",
        "# üîπ Install dependencies\n",
        "!pip install -q gradio faiss-cpu sentence-transformers requests langchain pypdf2 python-docx pandas\n",
        "\n",
        "# ------------------------------\n",
        "# Imports\n",
        "# ------------------------------\n",
        "import os\n",
        "import gradio as gr\n",
        "import faiss\n",
        "import requests\n",
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.docstore.document import Document\n",
        "from PyPDF2 import PdfReader\n",
        "import docx\n",
        "\n",
        "# ------------------------------\n",
        "# NVIDIA API Settings\n",
        "# ------------------------------\n",
        "NVIDIA_API_KEY = \"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\"   # üîë replace with your NVIDIA key\n",
        "NVIDIA_CHAT_URL = \"https://integrate.api.nvidia.com/v1/chat/completions\"\n",
        "\n",
        "headers = {\n",
        "    \"Authorization\": f\"Bearer {NVIDIA_API_KEY}\",\n",
        "    \"Content-Type\": \"application/json\"\n",
        "}\n",
        "\n",
        "# ------------------------------\n",
        "# Embedding + FAISS Setup\n",
        "# ------------------------------\n",
        "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "\n",
        "def load_file(file_path):\n",
        "    \"\"\"Reads text from PDF, DOCX, TXT, or CSV\"\"\"\n",
        "    ext = file_path.split(\".\")[-1].lower()\n",
        "    text = \"\"\n",
        "    if ext == \"pdf\":\n",
        "        reader = PdfReader(file_path)\n",
        "        text = \"\\n\".join([page.extract_text() for page in reader.pages if page.extract_text()])\n",
        "    elif ext == \"docx\":\n",
        "        doc = docx.Document(file_path)\n",
        "        text = \"\\n\".join([para.text for para in doc.paragraphs])\n",
        "    elif ext == \"csv\":\n",
        "        df = pd.read_csv(file_path)\n",
        "        text = df.astype(str).to_string()\n",
        "    else:  # assume txt\n",
        "        with open(file_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            text = f.read()\n",
        "    return text\n",
        "\n",
        "def build_faiss_index(docs):\n",
        "    \"\"\"Split docs ‚Üí create embeddings ‚Üí build FAISS index\"\"\"\n",
        "    chunks, texts = [], []\n",
        "    for doc in docs:\n",
        "        parts = splitter.split_text(doc)\n",
        "        chunks.extend([Document(page_content=p) for p in parts])\n",
        "    texts = [c.page_content for c in chunks]\n",
        "\n",
        "    vectors = embedder.encode(texts)\n",
        "    index = faiss.IndexFlatL2(vectors.shape[1])\n",
        "    index.add(vectors)\n",
        "\n",
        "    return index, texts\n",
        "\n",
        "# ------------------------------\n",
        "# NVIDIA Chat Function\n",
        "# ------------------------------\n",
        "def nvidia_llm(query, context=\"\"):\n",
        "    payload = {\n",
        "        \"model\": \"meta/llama-3.1-8b-instruct\",\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful school parent helpdesk assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Context:\\n{context}\\n\\nQuestion:\\n{query}\"}\n",
        "        ],\n",
        "        \"temperature\": 0.3\n",
        "    }\n",
        "    resp = requests.post(NVIDIA_CHAT_URL, headers=headers, json=payload)\n",
        "    return resp.json()[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "# ------------------------------\n",
        "# RAG Pipeline (Helpdesk Agent)\n",
        "# ------------------------------\n",
        "index, texts = None, []\n",
        "\n",
        "def rag_agent(query, history):\n",
        "    global index, texts\n",
        "    if index is None:\n",
        "        answer = \"‚ö†Ô∏è Please upload the school helpdesk PDF first.\"\n",
        "        history.append((query, answer))\n",
        "        return history, history\n",
        "\n",
        "    q_vec = embedder.encode([query])\n",
        "    D, I = index.search(q_vec, k=3)\n",
        "    context = \"\\n\".join([texts[i] for i in I[0]])\n",
        "\n",
        "    # Answer with context\n",
        "    answer = nvidia_llm(query, context)\n",
        "    history.append((query, answer))\n",
        "    return history, history\n",
        "\n",
        "def upload_and_build(file):\n",
        "    global index, texts\n",
        "    text = load_file(file.name)\n",
        "    index, texts = build_faiss_index([text])\n",
        "    return f\"‚úÖ Knowledge base built from {os.path.basename(file.name)}\"\n",
        "\n",
        "# ------------------------------\n",
        "# Gradio UI\n",
        "# ------------------------------\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## üè´ School Parent Helpdesk Chatbot\")\n",
        "\n",
        "    with gr.Row():\n",
        "        file_upload = gr.File(label=\"üìÇ Upload School Document\", file_types=[\".pdf\", \".txt\", \".docx\", \".csv\"])\n",
        "        upload_status = gr.Textbox(label=\"Upload Status\")\n",
        "\n",
        "    file_upload.upload(upload_and_build, file_upload, upload_status)\n",
        "\n",
        "    chat_ui = gr.Chatbot(label=\"üí¨ Ask about school facilities, enrollment, exam dates...\")\n",
        "    msg = gr.Textbox(label=\"Type your question here...\")\n",
        "    clear = gr.Button(\"Clear Chat\")\n",
        "\n",
        "    state = gr.State([])\n",
        "\n",
        "    msg.submit(rag_agent, [msg, state], [chat_ui, state])\n",
        "    clear.click(lambda: ([], []), None, [chat_ui, state])\n",
        "\n",
        "demo.launch(inline=True)  # Works in Colab\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.0"
    },
    "required_libs": []
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
